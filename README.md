# ğŸ“˜ Prueba de Concepto (PoC): Motor de BÃºsqueda SemÃ¡ntica + RAG LLM sobre Documentos en PostgreSQL (base64) y S3

## ğŸ¯ Objetivo General

Validar la viabilidad tÃ©cnica y eficiencia de implementar un sistema de
bÃºsqueda semÃ¡ntica y respuesta asistida por LLM (RAG - Retrieval
Augmented Generation) utilizando documentos almacenados en: - âœ…
PostgreSQL: en formato base64. - âœ… Storage S3: archivos binarios (PDF,
DOCX, TXT, etc.).

## ğŸ—ï¸ Arquitectura del flujo PoC

    PostgreSQL (base64 docs)   S3 (binary/PDF/etc.)
               â”‚                         â”‚
               â””â”€â”€â”€â”€â–¶ Extractor (Python) â”€â”˜
                            â”‚
           ğŸ§¾ DecodificaciÃ³n + Parsing (PDF/TXT/DOCX/TIKA)
                            â”‚
           ğŸ“ Chunking (divisiÃ³n del documento en bloques)
                            â”‚
     ğŸ§® GeneraciÃ³n de embeddings (OpenAI / HuggingFace)
                            â”‚
     ğŸ“¦ Almacenamiento en vector DB (PGVector / Qdrant / Pinecone)
                            â”‚
     ğŸ‘¤ Usuario consulta en lenguaje natural
                            â”‚
     ğŸ” Retrieval de Top-K similares + metadata
                            â”‚
     ğŸ¤– RAG con LLM (GPT/Llama/Mistral) â†’ Respuesta enriquecida

## ğŸ“¦ MÃ³dulos que deben implementarse (mÃ­nimo viable)

    1     ExtracciÃ³n PostgreSQL: Obtener documentos en base64 
            Output: Archivos binarios temporales
    
    2     ExtracciÃ³n desde S3: Descarga de archivos binarios 
            Output: Archivos locales                                 

    3     DecodificaciÃ³n   base64 â†’ PDF/DOCX/TXT 
            Output: Binary ready

    4     Parsing de contenido: Convertir binarios a texto
            Output: Texto limpio por documento                 

    5     Chunking: Dividir documentos en bloques Ãºtiles
            Output: Lista de chunks                     

    6     GeneraciÃ³n de embeddings: Crear vectores semÃ¡nticos
            Output: Matriz de embeddings                

    7     Almacenamiento en Vector DB: Persistencia de embeddings con metadata
            Output: Base vectorial consultable              

    8     Motor RAG: LLM + recuperaciÃ³n contextual
            Output: Respuestas enriquecidas                              

    9     MÃ©tricas y validaciÃ³n: Evaluar precisiÃ³n, recall, latencia
            Output: Informe PoC      

## ğŸ› ï¸ Stack TÃ©cnico Sugerido (PoC Ãgil)

| Componente       | OpciÃ³n Recomendada                         | Alternativa Self-Hosted            |
|------------------|---------------------------------------------|------------------------------------|
| **Lenguaje**     | Python 3.10+                                | Go, NodeJS                         |
| **Framework IA** | LangChain                                   | LlamaIndex                         |
| **Vector DB**    | pgvector (extensiÃ³n PostgreSQL existente)   | Qdrant / Weaviate                  |
| **Embeddings**   | OpenAI `text-embedding-3-large`             | InstructorXL (HuggingFace)         |
| **LLM**          | GPT-4o                                      | Llama 3 70B                        |
| **Storage**      | AWS S3                                      | MinIO                              |
| **Framework API**| FastAPI                                     | Flask                              |


## ğŸ“Š Criterios de Ã‰xito de la PoC

| MÃ©trica                  | Criterio Exitoso                         | ValidaciÃ³n / MÃ©todo                |
|---------------------------|------------------------------------------|------------------------------------|
| **Tiempo de respuesta**   | < 3s promedio para bÃºsqueda + RAG        | Prueba controlada                  |
| **Relevancia**            | â‰¥ 75% (feedback experto)                | Ranking manual / Q&A               |
| **Robustez**              | Indexar â‰¥ 100 documentos sin errores     | Prueba de estrÃ©s inicial           |
| **Costos**                | Alineado al presupuesto                  | EstimaciÃ³n mensual                 |
| **Facilidad de integraciÃ³n** | Integrable al pipeline actual          | ValidaciÃ³n de arquitectura         |
| **Escalabilidad**         | Proyectable a 10K documentos             | EvaluaciÃ³n tÃ©cnica                 |

## ğŸš€ PrÃ³ximos pasos (roadmap)

| Fase              | Actividad                                 | DuraciÃ³n estimada | Resultado           |
|-------------------|-------------------------------------------|-------------------|---------------------|
|âœ… 1              | Definir dataset inicial (100 docs mixtos) | 1 dÃ­a             | Scope PoC           |
|âœ… 2              | Preparar ambiente local                   | 1-2 dÃ­as          | Entorno configurado |
|ğŸ› ï¸ 3              | Implementar extracciÃ³n y parsing          | 2-3 dÃ­as          | Datos legibles      |
|ğŸ§  4              | Embedding + vector DB                     | 2 dÃ­as            | Vector DB activa    |
|ğŸ¤– 5              | RAG con interfaz simple funcional         | 2 dÃ­as            | Demostrador         |
|ğŸ“Š 6              | ValidaciÃ³n de precisiÃ³n                   | 1-2 dÃ­as          | Reporte PoC         |
|ğŸ“ 7              | EstimaciÃ³n de costos & escalado           | 1 dÃ­a             | Go/No-Go            |
  
## ğŸ“ Estructura sugerida de repositorio

    /poc-rag-docs/
    â”‚
    â”œâ”€â”€ ingestion/
    â”‚   â”œâ”€â”€ fetch_postgres.py
    â”‚   â”œâ”€â”€ fetch_s3.py
    â”‚   â”œâ”€â”€ decode_and_parse.py
    â”‚
    â”œâ”€â”€ vectorization/
    â”‚   â”œâ”€â”€ chunking.py
    â”‚   â”œâ”€â”€ embeddings.py
    â”‚   â”œâ”€â”€ vector_store.py
    â”‚
    â”œâ”€â”€ rag/
    â”‚   â”œâ”€â”€ retriever.py
    â”‚   â”œâ”€â”€ llm_handler.py
    â”‚
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ server.py (FastAPI)
    â”‚
    â”œâ”€â”€ config/
    â”‚   â”œâ”€â”€ settings.yaml
    â”‚
    â””â”€â”€ README.md


## ğŸ§© PLAN TÃ‰CNICO GRANULAR POR MÃ“DULO

### 1. ExtracciÃ³n PostgreSQL

    Objetivo: Obtener documentos codificados en base64 desde una tabla de PostgreSQL.
    
    Stack:
    
    psycopg2 o SQLAlchemy
    
    pandas (para manipular resultados)
    
    dotenv o pydantic para configuraciÃ³n
    
    Tareas:
    
    Conectar a la base PostgreSQL usando credenciales desde .env.
    
    Ejecutar query SELECT id, filename, data_base64 FROM documentos.
    
    Guardar cada resultado en /tmp/files/{id}_{filename}.
    
    Registrar logs de extracciÃ³n con timestamps.
    
    Manejar errores de conexiÃ³n y timeouts.
    
    Output: Archivos binarios temporales (base64 intactos).
    Criterio de Ã©xito: 100% de los registros vÃ¡lidos descargados.

### 2. ExtracciÃ³n desde S3

    Objetivo: Descargar archivos binarios (PDF, DOCX, TXT, etc.) desde buckets S3.
    
    Stack:
    
    boto3
    
    dotenv o yaml para configuraciones
    
    Tareas:
    
    Configurar conexiÃ³n a AWS S3 (credenciales IAM, regiÃ³n, bucket).
    
    Listar archivos bajo prefijo (/docs/).
    
    Descargar archivos a /tmp/files/.
    
    Validar tamaÃ±o y checksum.
    
    Manejar excepciones (ClientError, NoSuchKey).
    
    Output: Archivos locales descargados.
    Criterio de Ã©xito: 100% de los archivos descargados sin errores.

### 3. DecodificaciÃ³n

    Objetivo: Convertir documentos base64 a su formato original binario.
    
    Stack:
    
    base64
    
    os, io
    
    Tareas:
    
    Leer archivos .b64.
    
    Decodificar usando base64.b64decode().
    
    Guardar como .pdf, .docx, .txt segÃºn metadata.
    
    Validar integridad (intentos de apertura).
    
    Output: Archivos binarios â€œreadyâ€.
    Criterio de Ã©xito: Todos los archivos decodificables se convierten sin error.

### 4. Parsing de contenido

    Objetivo: Convertir documentos binarios a texto limpio.
    
    Stack:
    
    Apache Tika o textract
    
    pdfplumber / docx / PyMuPDF
    
    Tareas:
    
    Detectar tipo MIME (PDF, DOCX, TXT).
    
    Extraer texto.
    
    Limpiar saltos de lÃ­nea, caracteres no imprimibles, duplicados.
    
    Guardar .txt con mismo ID en /parsed/.
    
    Output: Texto plano por documento.
    Criterio de Ã©xito: â‰¥95% de texto legible en archivos vÃ¡lidos.

### 5. Chunking

    Objetivo: Dividir documentos en bloques Ãºtiles para embeddings.
    
    Stack:
    
    LangChain.text_splitter
    
    tiktoken (para limitar tokens)
    
    numpy o pandas
    
    Tareas:
    
    Definir tamaÃ±o de chunk (p.ej. 500 tokens con 50 de solapamiento).
    
    Aplicar sobre cada texto.
    
    Generar lista con chunk_id, source_id, text_chunk.
    
    Exportar DataFrame a /chunks/.
    
    Output: Lista de chunks listos para embedding.
    Criterio de Ã©xito: Todos los documentos divididos de forma consistente.

### 6. GeneraciÃ³n de embeddings

    Objetivo: Convertir chunks en vectores semÃ¡nticos.
    
    Stack:
    
    openai (text-embedding-3-large) o InstructorEmbedding (HF)
    
    tqdm para tracking
    
    Tareas:
    
    Cargar cada chunk de texto.
    
    Llamar API de embeddings en batch (manejar rate limits).
    
    Guardar vectores + metadata (chunk_id, source_id, embedding).
    
    Persistir en archivo parquet o JSONL.
    
    Output: Matriz de embeddings con metadata.
    Criterio de Ã©xito: â‰¥99% de embeddings generados correctamente.

### 7. Almacenamiento en Vector DB

    Objetivo: Persistir embeddings y metadata en pgvector o Qdrant.
    
    Stack:
    
    pgvector (PostgreSQL extension)
    
    SQLAlchemy / psycopg2
    
    Tareas:
    
    Crear tabla:
    
    CREATE TABLE documents_vectors (
      id SERIAL PRIMARY KEY,
      doc_id TEXT,
      chunk_id TEXT,
      content TEXT,
      embedding VECTOR(1536)
    );
    
    
    Insertar embeddings en batch.
    
    Implementar Ã­ndice vectorial (ivfflat).
    
    Verificar bÃºsqueda vectorial con cosine_distance.
    
    Output: Base vectorial consultable.
    Criterio de Ã©xito: Latencia < 300ms por consulta top-K.

### 8. Motor RAG

    Objetivo: Integrar recuperaciÃ³n semÃ¡ntica + LLM para generar respuestas.
    
    Stack:
    
    LangChain o LlamaIndex
    
    FastAPI
    
    OpenAI GPT-4o o Llama 3 70B
    
    Tareas:
    
    Implementar Retriever que:
    
    Reciba la query del usuario.
    
    Busque los top-K chunks similares.
    
    Implementar LLM Handler:
    
    Construya prompt contextual (query + chunks).
    
    Llame al modelo LLM.
    
    Devolver respuesta enriquecida + referencias.
    
    Output: Respuestas naturales con contexto citado.
    Criterio de Ã©xito: â‰¥75% de relevancia en validaciÃ³n manual.

### 9. MÃ©tricas y ValidaciÃ³n

    Objetivo: Medir precisiÃ³n, recall, latencia y robustez.
    
    Stack:
    
    scikit-learn (precision/recall)
    
    time, logging
    
    matplotlib o seaborn
    
    Tareas:
    
    Generar conjunto de Q&A de prueba.
    
    Medir:
    
    Tiempo total por consulta.
    
    Relevancia (top-K).
    
    Fallos por tipo de documento.
    
    Documentar resultados en reporte final PoC.
    
    Output: Informe con KPIs tÃ©cnicos y grÃ¡ficos.
    Criterio de Ã©xito: Cumplir mÃ©tricas definidas (<3s, â‰¥75% relevancia).

### 10. Infraestructura y Despliegue

    Objetivo: Ejecutar PoC de forma reproducible y portable.
    
    Stack:
    
    Docker Compose
    
    FastAPI + Uvicorn
    
    .env + settings.yaml
    
    Tareas:
    
    Crear contenedores para:
    
    API (FastAPI)
    
    PostgreSQL con extensiÃ³n pgvector
    
    Tika o extractor de texto
    
    Configurar red interna y volÃºmenes persistentes.
    
    Verificar endpoints /health, /query, /embedding.
    
    Output: PoC ejecutable con un solo comando.
    Criterio de Ã©xito: docker-compose up levanta entorno funcional completo.

### ğŸ“Š Resumen de dependencias entre mÃ³dulos
    PostgreSQL â”€â”
    S3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                 â†“
          ExtracciÃ³n + DecodificaciÃ³n
                 â†“
             Parsing â†’ Chunking
                 â†“
            Embeddings â†’ Vector DB
                 â†“
               RAG Engine
                 â†“
              ValidaciÃ³n
